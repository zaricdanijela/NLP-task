{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4fa3c4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                                           messages\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#  load dataset\n",
    "df = pd.read_csv('all-data.csv',names=['labels','messages'],encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f917472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "651e2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data cleaning and preprocessing\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sn = SnowballStemmer(language='english')\n",
    "corpus = []\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',df.messages[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in review if w not in set(stopwords.words('english'))]\n",
    "    review = [sn.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "   # review = ' '.[sn.stem(lemmatizer.lemmatize(w, get_wordnet_pos(w))) for w in review.lower().split() if w not in set(stopwords.words('english'))]\n",
    "    corpus.append(review)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ba9cd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "622fdb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       According to Gran , the company has no plans t...\n",
       "1       Technopolis plans to develop in stages an area...\n",
       "2       The international electronic industry company ...\n",
       "3       With the new production plant the company woul...\n",
       "4       According to the company 's updated strategy f...\n",
       "                              ...                        \n",
       "4841    LONDON MarketWatch -- Share prices ended lower...\n",
       "4842    Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4843    Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4844    Net sales of the Paper segment decreased to EU...\n",
       "4845    Sales in Finland decreased by 10.5 % in Januar...\n",
       "Name: messages, Length: 4846, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c155a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      "r\n",
      "v\n"
     ]
    }
   ],
   "source": [
    "print(get_wordnet_pos('love'))\n",
    "print(get_wordnet_pos('lovely'))\n",
    "print(get_wordnet_pos('loving'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f01a84fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accord gran compani plan move product russia although compani grow',\n",
       " 'technopoli plan develop stage area less squar meter order host compani work comput technolog telecommun statement say']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cc7a27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creating the Bag of Words model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus[0:2]).toarray()\n",
    "\n",
    "#  Creating the TF-IDF model\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cv = TfidfVectorizer()\n",
    "X1 = cv.fit_transform(corpus[0:2]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "da671839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accord' 'although' 'area' 'compani' 'comput' 'develop' 'gran' 'grow'\n",
      " 'host' 'less' 'meter' 'move' 'order' 'plan' 'product' 'russia' 'say'\n",
      " 'squar' 'stage' 'statement' 'technolog' 'technopoli' 'telecommun' 'work']\n",
      "[[0.32391104 0.32391104 0.         0.46093075 0.         0.\n",
      "  0.32391104 0.32391104 0.         0.         0.         0.32391104\n",
      "  0.         0.23046538 0.32391104 0.32391104 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.2499025  0.17780768 0.2499025  0.2499025\n",
      "  0.         0.         0.2499025  0.2499025  0.2499025  0.\n",
      "  0.2499025  0.17780768 0.         0.         0.2499025  0.2499025\n",
      "  0.2499025  0.2499025  0.2499025  0.2499025  0.2499025  0.2499025 ]]\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names_out())\n",
    "print(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0ebf8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = [0 if labels == \"negative\"\n",
    "             else 1 if labels == \"neutral\"\n",
    "             else 2 for labels in df[\"labels\"]]\n",
    "\n",
    "new_data['labels'] = [0 if labels == \"negative\"\n",
    "             else 1 if labels == \"neutral\"\n",
    "             else 2 for labels in new_data[\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ebcf805a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>0</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>1</td>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>0</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>0</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>0</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                           messages\n",
       "0          1  According to Gran , the company has no plans t...\n",
       "1          1  Technopolis plans to develop in stages an area...\n",
       "2          0  The international electronic industry company ...\n",
       "3          2  With the new production plant the company woul...\n",
       "4          2  According to the company 's updated strategy f...\n",
       "...      ...                                                ...\n",
       "4841       0  LONDON MarketWatch -- Share prices ended lower...\n",
       "4842       1  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4843       0  Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4844       0  Net sales of the Paper segment decreased to EU...\n",
       "4845       0  Sales in Finland decreased by 10.5 % in Januar...\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1fe18864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Multinomial Naive Bayes is :  67.7319587628866 %\n",
      "Accuracy Score for Logistic Regression is :  74.63917525773196 %\n",
      "Accuracy Score for Support Vector Machine is :  75.36082474226804 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\n",
    "\n",
    "y = df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size = 0.20, random_state = 0) #  try with X and X1\n",
    "\n",
    "#  Model training using Naive bayes classifier, Logistic Regression and SVC\n",
    "\n",
    "models = {\n",
    "    MultinomialNB():'Multinomial Naive Bayes',\n",
    "    LogisticRegression(max_iter=300):'Logistic Regression',\n",
    "    SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto'):'Support Vector Machine'\n",
    "}\n",
    "\n",
    "for m in models.keys():\n",
    "    m.fit(X_train,y_train)\n",
    "    \n",
    "for model,name in models.items():\n",
    "     print(f\"Accuracy Score for {name} is : \", model.score(X_test,y_test)*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2a21b725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\base_any2vec.py:742: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "list_of_lists = [nltk.word_tokenize(corpus) for corpus in corpus]\n",
    "\n",
    "    \n",
    "#  Creating model using Word2Vec\n",
    "\n",
    "model = Word2Vec(list_of_lists, window = 5, min_count = 1, sg = 0, hs = 1)\n",
    "\n",
    "#  Get 3 most similar words \n",
    "#similar = model.wv.most_similar(positive = ['industri'], topn = 3)\n",
    "#print(similar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0c562b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('maker', 0.9574943780899048), ('aspocomp', 0.9552718997001648), ('rautaruukki', 0.9550167918205261)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.wv.most_similar('compani', topn = 3)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "458c63c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6635804"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('russia', 'meter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f495b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [nltk.word_tokenize(corpus) for corpus in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "920953ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['accord',\n",
       "  'gran',\n",
       "  'compani',\n",
       "  'plan',\n",
       "  'move',\n",
       "  'product',\n",
       "  'russia',\n",
       "  'although',\n",
       "  'compani',\n",
       "  'grow'],\n",
       " ['technopoli',\n",
       "  'plan',\n",
       "  'develop',\n",
       "  'stage',\n",
       "  'area',\n",
       "  'less',\n",
       "  'squar',\n",
       "  'meter',\n",
       "  'order',\n",
       "  'host',\n",
       "  'compani',\n",
       "  'work',\n",
       "  'comput',\n",
       "  'technolog',\n",
       "  'telecommun',\n",
       "  'statement',\n",
       "  'say']]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "005b95ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('solut', 0.9810017347335815), ('provid', 0.9808456897735596), ('servic', 0.9806942939758301)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.wv.most_similar(positive=['develop'], topn = 3)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f08f8605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.36035865e-02,  5.80423959e-02, -7.27785751e-02,  1.32263377e-02,\n",
       "       -3.38913649e-02, -1.02723492e-02, -4.37395163e-02, -2.98373476e-02,\n",
       "       -1.39214536e-02, -3.56604978e-02, -3.56875695e-02, -1.57713890e-02,\n",
       "        2.73840278e-02, -1.07569229e-02,  1.64680686e-02, -3.34480144e-02,\n",
       "       -3.31588499e-02,  5.95135130e-02, -2.26852037e-02,  1.08586363e-01,\n",
       "       -8.44427496e-02,  9.23120752e-02,  2.28032265e-02,  9.54171177e-03,\n",
       "        9.62206945e-02, -7.79979080e-02,  3.09958551e-02,  1.00962013e-01,\n",
       "       -2.19753035e-03, -2.49636844e-02,  9.02668536e-02, -1.75293721e-02,\n",
       "        4.40836558e-03,  5.49590252e-02,  5.03864847e-02,  9.44275334e-02,\n",
       "       -2.83048925e-04, -6.04072912e-03, -5.90352388e-03,  4.33618948e-03,\n",
       "        2.83837896e-02,  4.06741463e-02,  5.88304922e-03, -7.64686838e-02,\n",
       "       -3.09005566e-02, -1.11655938e-02, -8.45301077e-02, -1.38409454e-02,\n",
       "       -5.40145338e-02, -3.74493864e-03, -1.85833555e-02,  4.04233811e-03,\n",
       "        1.52278580e-02,  2.02406216e-02,  1.96747649e-02,  7.64054134e-02,\n",
       "       -1.17438346e-01, -6.08217902e-02,  3.57738659e-02, -4.01246101e-02,\n",
       "        9.22296196e-02,  5.52370474e-02, -5.93946390e-02,  1.93785839e-02,\n",
       "       -1.11013614e-02,  4.23194617e-02, -4.47794003e-03, -4.37316447e-02,\n",
       "        3.93872112e-02,  2.95780636e-02, -3.18587124e-02, -6.27738656e-03,\n",
       "       -2.72581447e-02,  4.54167314e-02, -6.61155432e-02, -6.02425188e-02,\n",
       "       -4.12545502e-02, -3.61485630e-02,  5.87529801e-02,  5.93174212e-02,\n",
       "       -2.45756246e-02, -5.41259833e-02,  3.12074926e-03, -1.35088265e-01,\n",
       "       -1.12125796e-04,  9.95825138e-03,  7.07384348e-02,  3.66936289e-02,\n",
       "       -9.55364015e-03, -3.53532210e-02, -4.20508943e-02, -7.21322699e-03,\n",
       "        6.66501969e-02,  5.39377369e-02, -1.08028546e-01, -1.40626468e-02,\n",
       "       -3.55569795e-02,  5.96269183e-02, -4.22778204e-02, -3.94210555e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['compani']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8221f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#  Embeddings\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for j in range(0,len(list_of_lists)):\n",
    "    temp = []\n",
    "    for i in range(0, len(list_of_lists[j])):\n",
    "        temp.append(model.wv[list_of_lists[j][i]])\n",
    "    if(len(temp)>0):\n",
    "        embeddings.append(np.average(temp, axis = 0))\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "de9498d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Multinomial Naive Bayes is :  57.06914344685242 %\n",
      "Accuracy Score for Random Forest Classifier is :  62.848297213622295 %\n",
      "Accuracy Score for Support Vector Machine is :  64.49948400412796 %\n",
      "Accuracy Score for Logistic Regression is :  64.49948400412796 %\n"
     ]
    }
   ],
   "source": [
    "#  Model training using Naive bayes classifier, Logistic Regression, SVC and RFC with Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y1 = novidata['labels']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(embeddings, y1, test_size = 0.20, random_state = 0)\n",
    "\n",
    "#  Needs scaler for MNB (negative values in vectors)\n",
    "scaler = MinMaxScaler()\n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_test1 = scaler.transform(X_test1)\n",
    "\n",
    "models1 = {\n",
    "    MultinomialNB():'Multinomial Naive Bayes',\n",
    "    RandomForestClassifier(n_estimators = 20, random_state = 0):'Random Forest Classifier',\n",
    "    SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto'): 'Support Vector Machine',\n",
    "    LogisticRegression(max_iter = 300):'Logistic Regression'\n",
    "}\n",
    "\n",
    "for m in models1.keys():\n",
    "    m.fit(X_train1, y_train1)\n",
    "    \n",
    "for model, name in models1.items():\n",
    "     print(f\"Accuracy Score for {name} is : \", model.score(X_test1, y_test1)*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "67bd7b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cba881",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cfeaefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_b = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "model_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2555f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52636856",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model_b.encode(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76da0662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Multinomial Naive Bayes is :  64.3298969072165 %\n",
      "Accuracy Score for Random Forest Classifier is :  67.62886597938144 %\n",
      "Accuracy Score for Support Vector Machine is :  73.19587628865979 %\n"
     ]
    }
   ],
   "source": [
    "#  Model training using Naive bayes classifier, Logistic Regression, SVC and RFC with BERT\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(embeddings, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "#  Needs scaler for MNB (negative values in vectors)\n",
    "scaler = MinMaxScaler()\n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_test1 = scaler.transform(X_test1)\n",
    "\n",
    "models_b = {\n",
    "    MultinomialNB():'Multinomial Naive Bayes',\n",
    "    RandomForestClassifier(n_estimators = 20, random_state = 0):'Random Forest Classifier',\n",
    "    SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto'): 'Support Vector Machine',\n",
    "   # LogisticRegression(max_iter = 300):'Logistic Regression'\n",
    "}\n",
    "\n",
    "for m in models_b.keys():\n",
    "    m.fit(X_train1, y_train1)\n",
    "    \n",
    "for model, name in models_b.items():\n",
    "     print(f\"Accuracy Score for {name} is : \", model.score(X_test1, y_test1)*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a64e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
